{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28284893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "820cac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 2025-01-01...\n",
      "Scraping 2025-01-02...\n",
      "Scraping 2025-01-03...\n",
      "Scraping 2025-01-04...\n",
      "Scraping 2025-01-05...\n",
      "Scraping 2025-01-06...\n",
      "Scraping 2025-01-07...\n",
      "Scraping 2025-01-08...\n",
      "Scraping 2025-01-09...\n",
      "Scraping 2025-01-10...\n",
      "Scraping 2025-01-11...\n",
      "Scraping 2025-01-12...\n",
      "Scraping 2025-01-13...\n",
      "Scraping 2025-01-14...\n",
      "Scraping 2025-01-15...\n",
      "Scraping 2025-01-16...\n",
      "Scraping 2025-01-17...\n",
      "Scraping 2025-01-18...\n",
      "Scraping 2025-01-19...\n",
      "Scraping 2025-01-20...\n",
      "Scraping 2025-01-21...\n",
      "Scraping 2025-01-22...\n",
      "Scraping 2025-01-23...\n",
      "Scraping 2025-01-24...\n",
      "Scraping 2025-01-25...\n",
      "Scraping 2025-01-26...\n",
      "Scraping 2025-01-27...\n",
      "Scraping 2025-01-28...\n",
      "Scraping 2025-01-29...\n",
      "Scraping 2025-01-30...\n",
      "Scraping 2025-01-31...\n",
      "Scraping 2025-02-01...\n",
      "Scraping 2025-02-02...\n",
      "Scraping 2025-02-03...\n",
      "Scraping 2025-02-04...\n",
      "Scraping 2025-02-05...\n",
      "Scraping 2025-02-06...\n",
      "Scraping 2025-02-07...\n",
      "Scraping 2025-02-08...\n",
      "Scraping 2025-02-09...\n",
      "Scraping 2025-02-10...\n",
      "Scraping 2025-02-11...\n",
      "Scraping 2025-02-12...\n",
      "Scraping 2025-02-13...\n",
      "Scraping 2025-02-14...\n",
      "Scraping 2025-02-15...\n",
      "Scraping 2025-02-16...\n",
      "Scraping 2025-02-17...\n",
      "Scraping 2025-02-18...\n",
      "Scraping 2025-02-19...\n",
      "Scraping 2025-02-20...\n",
      "Scraping 2025-02-21...\n",
      "Scraping 2025-02-22...\n",
      "Scraping 2025-02-23...\n",
      "Scraping 2025-02-24...\n",
      "Scraping 2025-02-25...\n",
      "Scraping 2025-02-26...\n",
      "Scraping 2025-02-27...\n",
      "Scraping 2025-02-28...\n",
      "Scraping 2025-03-01...\n",
      "Scraping 2025-03-02...\n",
      "Scraping 2025-03-03...\n",
      "Scraping 2025-03-04...\n",
      "Scraping 2025-03-05...\n",
      "Scraping 2025-03-06...\n",
      "Scraping 2025-03-07...\n",
      "Scraping 2025-03-08...\n",
      "Scraping 2025-03-09...\n",
      "Scraping 2025-03-10...\n",
      "Scraping 2025-03-11...\n",
      "Scraping 2025-03-12...\n",
      "Scraping 2025-03-13...\n",
      "Scraping 2025-03-14...\n",
      "Scraping 2025-03-15...\n",
      "Scraping 2025-03-16...\n",
      "Scraping 2025-03-17...\n",
      "Scraping 2025-03-18...\n",
      "Scraping 2025-03-19...\n",
      "Scraping 2025-03-20...\n",
      "Scraping 2025-03-21...\n",
      "Scraping 2025-03-22...\n",
      "Scraping 2025-03-23...\n",
      "Scraping 2025-03-24...\n",
      "Scraping 2025-03-25...\n",
      "Scraping 2025-03-26...\n",
      "Scraping 2025-03-27...\n",
      "Scraping 2025-03-28...\n",
      "Scraping 2025-03-29...\n",
      "Scraping 2025-03-30...\n",
      "Scraping 2025-03-31...\n",
      "Scraping 2025-04-01...\n",
      "Scraping 2025-04-02...\n",
      "Scraping 2025-04-03...\n",
      "Scraping 2025-04-04...\n",
      "Scraping 2025-04-05...\n",
      "Scraping 2025-04-06...\n",
      "Scraping 2025-04-07...\n",
      "Scraping 2025-04-08...\n",
      "Scraping 2025-04-09...\n",
      "Scraping 2025-04-10...\n",
      "Scraping 2025-04-11...\n",
      "Scraping 2025-04-12...\n",
      "Scraping 2025-04-13...\n",
      "Scraping 2025-04-14...\n",
      "Scraping 2025-04-15...\n",
      "Scraping 2025-04-16...\n",
      "Scraping 2025-04-17...\n",
      "Scraping 2025-04-18...\n",
      "Scraping 2025-04-19...\n",
      "Scraping 2025-04-20...\n",
      "Scraping 2025-04-21...\n",
      "Scraping 2025-04-22...\n",
      "Scraping 2025-04-23...\n",
      "Scraping 2025-04-24...\n",
      "Scraping 2025-04-25...\n",
      "Scraping 2025-04-26...\n",
      "Scraping 2025-04-27...\n",
      "Scraping 2025-04-28...\n",
      "Scraping 2025-04-29...\n",
      "Scraping 2025-04-30...\n",
      "Scraping 2025-05-01...\n",
      "Scraping 2025-05-02...\n",
      "Scraping 2025-05-03...\n",
      "Scraping 2025-05-04...\n",
      "Scraping 2025-05-05...\n",
      "Scraping 2025-05-06...\n",
      "Scraping 2025-05-07...\n",
      "Scraping 2025-05-08...\n",
      "Scraping 2025-05-09...\n",
      "Scraping 2025-05-10...\n",
      "Scraping 2025-05-11...\n",
      "Scraping 2025-05-12...\n",
      "Scraping 2025-05-13...\n",
      "Scraping 2025-05-14...\n",
      "Scraping 2025-05-15...\n",
      "Scraping 2025-05-16...\n",
      "Scraping 2025-05-17...\n",
      "Scraping 2025-05-18...\n",
      "Scraping 2025-05-19...\n",
      "Scraping 2025-05-20...\n",
      "Scraping 2025-05-21...\n",
      "Scraping 2025-05-22...\n",
      "Scraping 2025-05-23...\n",
      "Scraping 2025-05-24...\n",
      "Scraping 2025-05-25...\n",
      "Scraping 2025-05-26...\n",
      "Scraping 2025-05-27...\n",
      "Scraping 2025-05-28...\n",
      "Scraping 2025-05-29...\n",
      "Scraping 2025-05-30...\n",
      "Scraping 2025-05-31...\n",
      "Scraping 2025-06-01...\n",
      "Scraping 2025-06-02...\n",
      "Scraping 2025-06-03...\n",
      "Scraping 2025-06-04...\n",
      "Scraping 2025-06-05...\n",
      "Scraping 2025-06-06...\n",
      "Scraping 2025-06-07...\n",
      "Scraping 2025-06-08...\n",
      "Scraping 2025-06-09...\n",
      "Scraping 2025-06-10...\n",
      "Scraping 2025-06-11...\n",
      "Scraping 2025-06-12...\n",
      "Scraping 2025-06-13...\n",
      "Scraping 2025-06-14...\n",
      "Scraping 2025-06-15...\n",
      "Scraping 2025-06-16...\n",
      "Scraping 2025-06-17...\n",
      "Scraping 2025-06-18...\n",
      "Scraping 2025-06-19...\n",
      "Scraping 2025-06-20...\n",
      "Scraping 2025-06-21...\n",
      "Scraping 2025-06-22...\n",
      "Scraping 2025-06-23...\n",
      "Scraping 2025-06-24...\n",
      "Scraping 2025-06-25...\n",
      "Scraping 2025-06-26...\n",
      "Scraping 2025-06-27...\n",
      "Scraping 2025-06-28...\n",
      "Scraping 2025-06-29...\n",
      "Scraping 2025-06-30...\n",
      "Scraping 2025-07-01...\n",
      "Scraping 2025-07-02...\n",
      "Scraping 2025-07-03...\n",
      "Scraping 2025-07-04...\n",
      "Scraping 2025-07-05...\n",
      "Scraping 2025-07-06...\n",
      "Scraping 2025-07-07...\n",
      "Scraping 2025-07-08...\n",
      "Scraping 2025-07-09...\n",
      "Scraping 2025-07-10...\n",
      "Scraping 2025-07-11...\n",
      "Scraping 2025-07-12...\n",
      "Scraping 2025-07-13...\n",
      "Scraping 2025-07-14...\n",
      "Scraping 2025-07-15...\n",
      "Scraping 2025-07-16...\n",
      "Scraping 2025-07-17...\n",
      "Scraping 2025-07-18...\n",
      "Scraping 2025-07-19...\n",
      "Scraping 2025-07-20...\n",
      "Scraping 2025-07-21...\n",
      "Scraping 2025-07-22...\n",
      "Scraping 2025-07-23...\n",
      "Scraping 2025-07-24...\n",
      "Scraping 2025-07-25...\n",
      "Scraping 2025-07-26...\n",
      "Scraping 2025-07-27...\n",
      "Scraping 2025-07-28...\n",
      "Scraping 2025-07-29...\n",
      "Scraping 2025-07-30...\n",
      "Scraping 2025-07-31...\n",
      "✅ Données enregistrées dans meteo_dakar_mai_juil_2025.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 1. Config navigateur\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# 2. Définir la période (7 mois)\n",
    "start_date = date(2025, 1, 1)\n",
    "end_date = date(2025, 7, 31)\n",
    "\n",
    "data = []\n",
    "current_date = start_date\n",
    "\n",
    "# 3. Boucle sur chaque jour\n",
    "while current_date <= end_date:\n",
    "    day = current_date.day\n",
    "    month = current_date.month\n",
    "    url = f\"https://www.meteoart.com/africa/senegal/dakar?page=past-weather#day={day}&month={month}\"\n",
    "    print(f\"Scraping {current_date}...\")\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # attendre que le JS charge\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    try:\n",
    "        temp_max = soup.find(\"span\", id=\"max-temp\").text.strip()\n",
    "        temp_min = soup.find(\"span\", id=\"min-temp\").text.strip()\n",
    "        rain = soup.find(\"div\", id=\"bubble-rain\").text.strip()\n",
    "        wind = soup.find(\"div\", id=\"bubble-wind\").text.strip()\n",
    "        humidity = soup.find(\"div\", id=\"bubble-humidity\").text.strip()\n",
    "        \n",
    "        data.append({\n",
    "            \"date\": current_date.isoformat(),\n",
    "            \"temp_max\": temp_max.replace(',', '.'),\n",
    "            \"temp_min\": temp_min.replace(',', '.'),\n",
    "            \"precipitations_mm\": rain.replace(',', '.'),\n",
    "            \"wind_kmh\": wind,\n",
    "            \"humidity_percent\": humidity.replace(',', '.')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Données manquantes pour {current_date} : {e}\")\n",
    "\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# 4. Sauvegarder dans un CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"meteo_dakar_mai_juil_2025.csv\", index=False)\n",
    "print(\"✅ Données enregistrées dans meteo_dakar_mai_juil_2025.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3916400e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
